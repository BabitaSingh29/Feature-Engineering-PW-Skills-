{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b0b1354-a226-4c0b-98c7-e44e20716f6d",
   "metadata": {},
   "source": [
    "## Q1: What are missing values in a dataset? Why is it essential to handle missing values? Name some algorithms that are not affected by missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b322a1-aedc-46cf-94ba-971cc0ddda11",
   "metadata": {},
   "source": [
    "Missing values in a dataset refer to the absence of data in one or more variables for some observations. There can be various reasons for missing values, such as data entry errors, incomplete data collection, or the missingness may be intentional or due to a problem in the data collection process.\n",
    "\n",
    "Handling missing values is crucial because they can lead to biased or incorrect results if ignored. The presence of missing values can also reduce the sample size, which can affect the accuracy of the analysis. Therefore, it is important to handle missing values appropriately to ensure the validity of the results.\n",
    "\n",
    "Some of the algorithms that are not affected by missing values are:\n",
    "\n",
    "(i) Decision Trees: Decision Trees can handle missing values in both categorical and numerical data.\n",
    "\n",
    "(ii) Random Forest: Random Forest is an ensemble of decision trees and can handle missing values effectively.\n",
    "\n",
    "(iii) K-Nearest Neighbors (KNN): KNN can work with missing values, but the missing values need to be imputed before the algorithm can be applied.\n",
    "\n",
    "(iv) Support Vector Machines (SVM): SVM can handle missing values by replacing them with the mean or median value of the variable.\n",
    "\n",
    "(v) Naive Bayes: Naive Bayes can work with missing values by ignoring the missing values and using only the available data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084874f5-595b-4729-bf21-84e456617c15",
   "metadata": {},
   "source": [
    "## Q2: List down techniques used to handle missing data. Give an example of each with python code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f39382-8e58-4576-a6e8-206a09c7a70d",
   "metadata": {},
   "source": [
    "There are several techniques that can be used to handle missing data in a dataset. Some of the commonly used techniques are:\n",
    "\n",
    "(i) Deletion: In this technique, the rows or columns with missing values are deleted from the dataset. This technique is suitable when the missing values are randomly distributed and the deleted data does not have a significant impact on the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3737069c-fcfd-41aa-9202-07aa9e9a3962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B     C\n",
      "0  1.0  5.0  10.0\n",
      "3  4.0  8.0  13.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# creating a sample dataframe with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, None], 'B': [5, None, 7, 8, 9], 'C': [10, 11, None, 13, 14]})\n",
    "# dropping rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598916f9-1eae-4c22-baa4-a5ddaaf7ab21",
   "metadata": {},
   "source": [
    "(ii) Mean/Mode/Median Imputation: In this technique, the missing values are replaced with the mean/mode/median value of the variable. This technique is suitable when the missing values are missing at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d6ce355-46fa-44e6-930a-5e2241385175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B     C\n",
      "0  1.0  5.0  10.0\n",
      "1  2.0  NaN  11.0\n",
      "2  3.0  7.0   NaN\n",
      "3  4.0  8.0  13.0\n",
      "4  2.5  9.0  14.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# creating a sample dataframe with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, 3, 4, None], 'B': [5, None, 7, 8, 9], 'C': [10, 11, None, 13, 14]})\n",
    "\n",
    "# mean imputation for column A\n",
    "df['A'].fillna(df['A'].mean(), inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e97120a-9007-4214-9c73-ee79fdd7c9bb",
   "metadata": {},
   "source": [
    "(iii) Interpolation: In this technique, the missing values are estimated based on the values of other variables. This technique is suitable when the missing values have a temporal or spatial correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a29e55f-72f7-4893-97ef-12bdf6222d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B     C\n",
      "0  1.0  5.0   NaN\n",
      "1  2.0  6.0  11.0\n",
      "2  3.0  7.0  12.0\n",
      "3  4.0  NaN  13.0\n",
      "4  5.0  9.0   NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# creating a sample dataframe with missing values\n",
    "df = pd.DataFrame({'A': [1, 2, None, 4, 5], 'B': [5, 6, 7, None, 9], 'C': [None, 11, 12, 13, None]})\n",
    "\n",
    "# linear interpolation for column A\n",
    "df['A'].interpolate(method='linear', inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e866bf-a596-49a8-a412-0873c95c35d3",
   "metadata": {},
   "source": [
    "(iv) K-Nearest Neighbors Imputation: In this technique, the missing values are imputed by finding the K-nearest neighbors based on the distance metric and imputing the missing values with the mean or mode of the neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d65ca898-7109-47a4-a6ff-1bc496913e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A     B         C\n",
      "0  1.0   6.0  3.000000\n",
      "1  2.0   8.0  4.000000\n",
      "2  3.0   8.0  4.333333\n",
      "3  2.0   8.0  6.000000\n",
      "4  5.0  10.0  4.333333\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# create a sample dataset with missing values\n",
    "data = pd.DataFrame({'A': [1, 2, 3, None, 5], 'B': [6, None, 8, None, 10], 'C': [3, 4, None, 6, None]})\n",
    "\n",
    "# create a KNN imputer\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "# impute the missing values\n",
    "imputed_data = imputer.fit_transform(data)\n",
    "\n",
    "# convert the imputed data back to a DataFrame\n",
    "imputed_data = pd.DataFrame(imputed_data, columns=data.columns)\n",
    "\n",
    "# print the imputed data\n",
    "print(imputed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f2bafa-e5d1-42fd-9063-e42dec1834bf",
   "metadata": {},
   "source": [
    "## Q3: Explain the imbalanced data. What will happen if imbalanced data is not handled?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e15d7cb-18ae-4b27-a4b4-772eed8eca8a",
   "metadata": {},
   "source": [
    "Imbalanced data refers to a dataset where the number of observations in each class or category is not equal or roughly equal. This means that some classes have much fewer observations than others. For example, in a binary classification problem where the target variable is either 0 or 1, if there are many more observations of 0 than of 1 (or vice versa), the data is considered imbalanced.\n",
    "\n",
    "If imbalanced data is not handled, it can lead to biased model performance and poor predictive accuracy. This is because most machine learning algorithms are designed to optimize overall accuracy or error rate, and in an imbalanced dataset, this can lead to a bias towards the majority class. For example, if a dataset has 90% observations in the majority class and only 10% in the minority class, a model that always predicts the majority class would achieve an accuracy of 90%, even though it is not actually predicting the minority class correctly.\n",
    "\n",
    "In addition, imbalanced data can also lead to poor generalization performance, as the model may not learn to accurately predict the minority class, which can be important in many real-world applications. This is particularly problematic when the minority class represents a rare event or a critical outcome, such as fraud detection, disease diagnosis, or credit risk assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f9f91-0028-4f58-9547-d2728fc8a084",
   "metadata": {},
   "source": [
    "## Q4: What are Up-sampling and Down-sampling? Explain with an example when up-sampling and down- sampling are required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928b1ac-0ff7-43e5-a68b-005a15016d46",
   "metadata": {},
   "source": [
    "Up-sampling and down-sampling are two techniques used to handle imbalanced data in machine learning. In an imbalanced dataset, the number of observations in one class is significantly higher or lower than the other. Up-sampling involves creating more observations in the minority class to balance the distribution, while down-sampling involves reducing the number of observations in the majority class. For example, in fraud detection, there may be only a few fraudulent transactions compared to a large number of legitimate transactions. In this case, up-sampling can be used to create more fraudulent transactions and balance the dataset. Similarly, in cancer diagnosis, there may be a lot of healthy samples compared to cancerous samples. Here, down-sampling can be used to reduce the number of healthy samples and balance the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64844b1-e319-40cf-a906-79dd60b7b675",
   "metadata": {},
   "source": [
    "## Q5: What is data Augmentation? Explain SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5079a24-731a-42ad-bc6f-594debc62d9a",
   "metadata": {},
   "source": [
    "Data augmentation is a technique used to increase the amount of data available for training a machine learning model by creating new synthetic samples from existing ones. SMOTE (Synthetic Minority Over-sampling Technique) is a popular data augmentation method for imbalanced datasets, which creates synthetic minority class samples by interpolating between existing minority class samples. This technique helps to address the problem of class imbalance by increasing the number of minority class samples and making the dataset more balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3610f538-5706-41a0-81a8-3749008ee47f",
   "metadata": {},
   "source": [
    "## Q6: What are outliers in a dataset? Why is it essential to handle outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccead1b-41a3-4d4d-9e54-291db6ea27ae",
   "metadata": {},
   "source": [
    "Outliers are observations or data points that are significantly different from the other observations in a dataset. They can be either too large or too small in comparison to the other values in the dataset. Outliers can occur due to errors in data collection or entry, measurement errors, or natural variations in the data.\n",
    "\n",
    "Handling outliers is essential because they can significantly affect the statistical properties of a dataset and the performance of a machine learning model. Outliers can distort the mean and variance of a dataset, affecting the accuracy of statistical analyses and machine learning models. They can also result in overfitting of the model to the outliers, leading to poor generalization to new data. Therefore, it is essential to identify and handle outliers appropriately to ensure accurate and reliable analyses and model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26535836-ba3e-4cc7-a3a2-9861d93ff47f",
   "metadata": {},
   "source": [
    "## Q7: You are working on a project that requires analyzing customer data. However, you notice that some of the data is missing. What are some techniques you can use to handle the missing data in your analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93976d1-a003-476b-a815-72da54f5a983",
   "metadata": {},
   "source": [
    "There are several techniques that can be used to handle missing data in customer data analysis. Here are some of them:\n",
    "\n",
    "(i) Deletion: If the missing values are a small proportion of the data, you can delete the rows or columns containing missing values. This technique is suitable for cases where the missing data is random, and deleting the missing values does not affect the analysis significantly.\n",
    "\n",
    "(ii) Imputation: If the missing values are a large proportion of the data, you can use imputation techniques to fill in the missing values. Mean imputation, mode imputation, and regression imputation are some of the commonly used techniques for imputing missing values.\n",
    "\n",
    "(iii) Model-based imputation: You can use a machine learning model to predict the missing values based on the other variables in the dataset.\n",
    "\n",
    "(iv) Multiple imputation: This involves creating multiple imputed datasets by randomly filling in the missing values based on their distribution. The analysis is then performed on each imputed dataset, and the results are combined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9221304a-5e03-45a5-ad99-4ccd96406dac",
   "metadata": {},
   "source": [
    "## Q8: You are working with a large dataset and find that a small percentage of the data is missing. What are some strategies you can use to determine if the missing data is missing at random or if there is a pattern to the missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188c4cf-18e0-4a19-8117-f914b4ca626d",
   "metadata": {},
   "source": [
    "To determine if the missing data is missing at random or if there is a pattern to the missing data, you can use the following strategies:\n",
    "\n",
    "Visual inspection: You can create visualizations of the missing data, such as heatmaps or missing data plots, to identify patterns in the missing data.\n",
    "\n",
    "Statistical tests: You can use statistical tests such as Little's MCAR test or the chi-square test to determine if the missing data is missing completely at random (MCAR), missing at random (MAR), or missing not at random (MNAR).\n",
    "\n",
    "Imputation and analysis: You can impute the missing data using different imputation techniques and compare the results of the analysis to identify any significant differences between the imputed and non-imputed data. This can help to identify any patterns in the missing data.\n",
    "\n",
    "Domain knowledge: You can also use your domain knowledge to determine if there is a pattern to the missing data. For example, if certain demographic variables have more missing data, it may indicate a pattern in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae54966-fec0-4300-919d-148a502c3822",
   "metadata": {},
   "source": [
    "## Q9: Suppose you are working on a medical diagnosis project and find that the majority of patients in the dataset do not have the condition of interest, while a small percentage do. What are some strategies you can use to evaluate the performance of your machine learning model on this imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909c1b16-952f-45ab-9d9e-22ddbcf60266",
   "metadata": {},
   "source": [
    "When working on a medical diagnosis project with an imbalanced dataset, the first step is to select appropriate evaluation metrics that are sensitive to the minority class, such as precision, recall, and F1-score. Resampling techniques such as oversampling, undersampling, and SMOTE can be used to balance the dataset before training the model. Another strategy is to use cost-sensitive learning where misclassification of the minority class is given more weight than the majority class during training. It is important to use a combination of evaluation metrics and resampling techniques to ensure the model's performance is robust on imbalanced datasets. Additionally, domain experts should be consulted to ensure the model's predictions are accurate and clinically relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb4ff89-751b-4a20-8efa-c8e559abca28",
   "metadata": {},
   "source": [
    "## Q10: When attempting to estimate customer satisfaction for a project, you discover that the dataset is unbalanced, with the bulk of customers reporting being satisfied. What methods can you employ to balance the dataset and down-sample the majority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f07737-900a-426a-94e6-d367bb50aa97",
   "metadata": {},
   "source": [
    "When dealing with an unbalanced dataset where the majority class dominates, some methods that can be employed to balance the dataset include:\n",
    "\n",
    "Undersampling: randomly removing samples from the majority class to balance the dataset.\n",
    "\n",
    "Oversampling: replicating samples from the minority class to balance the dataset.\n",
    "\n",
    "Synthetic Minority Over-sampling Technique (SMOTE): generating new synthetic samples by interpolating between existing samples of the minority class.\n",
    "\n",
    "To down-sample the majority class, undersampling can be used by randomly removing samples from the majority class. This method can result in the loss of important information from the majority class. However, oversampling or SMOTE can be used to generate synthetic samples for the minority class, which can increase the size of the minority class and balance the dataset. It is important to select the appropriate method based on the dataset and problem domain to ensure the model's performance is robust on the balanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71200cc4-d7b8-4099-866b-454332ffa1a5",
   "metadata": {},
   "source": [
    "## Q11: You discover that the dataset is unbalanced with a low percentage of occurrences while working on a project that requires you to estimate the occurrence of a rare event. What methods can you employ to balance the dataset and up-sample the minority class?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c0e473-55b9-4b9f-8c23-f6da7b1adc27",
   "metadata": {},
   "source": [
    "When dealing with an unbalanced dataset with a low percentage of occurrences, some methods that can be employed to balance the dataset include:\n",
    "\n",
    "Oversampling: replicating samples from the minority class to balance the dataset.\n",
    "\n",
    "Synthetic Minority Over-sampling Technique (SMOTE): generating new synthetic samples by interpolating between existing samples of the minority class.\n",
    "\n",
    "Upsampling can be used to increase the size of the minority class by replicating samples from the minority class. However, this method can lead to overfitting of the model to the minority class. To avoid overfitting, SMOTE can be used to generate synthetic samples that are similar to the minority class, but not exact replicas. It is important to select the appropriate method based on the dataset and problem domain to ensure the model's performance is robust on the balanced dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
